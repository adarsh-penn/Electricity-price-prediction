{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfxC5KY-glG2"
   },
   "source": [
    "# **Auto encoders with Bidirectional LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JB1sUG_gkrm",
    "outputId": "60b56421-191f-4746-ca7c-668b60544489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\Danie\\anaconda3\\envs\\XDS\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (2.1.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Using cached scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "Installing collected packages: scikit-learn, pandas\n",
      "Successfully installed pandas-2.2.3 scikit-learn-1.5.2\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "   ---------------------------------------- 0.0/390.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/390.0 MB 20.0 MB/s eta 0:00:20\n",
      "    --------------------------------------- 7.3/390.0 MB 19.7 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 11.3/390.0 MB 19.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 13.1/390.0 MB 19.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 13.6/390.0 MB 14.5 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 19.4/390.0 MB 15.9 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 23.9/390.0 MB 17.0 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 28.8/390.0 MB 17.9 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 33.6/390.0 MB 18.5 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 39.1/390.0 MB 19.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 44.8/390.0 MB 19.7 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 49.0/390.0 MB 19.9 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 53.7/390.0 MB 19.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 58.2/390.0 MB 19.9 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 62.9/390.0 MB 20.2 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 67.6/390.0 MB 20.3 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 73.1/390.0 MB 20.6 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 78.1/390.0 MB 20.8 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 83.9/390.0 MB 21.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 88.9/390.0 MB 21.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 94.1/390.0 MB 21.4 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 99.4/390.0 MB 21.4 MB/s eta 0:00:14\n",
      "   ---------- ---------------------------- 105.1/390.0 MB 21.4 MB/s eta 0:00:14\n",
      "   ---------- ---------------------------- 109.8/390.0 MB 21.5 MB/s eta 0:00:14\n",
      "   ----------- --------------------------- 114.6/390.0 MB 21.5 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 119.0/390.0 MB 21.5 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 123.5/390.0 MB 21.5 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 128.2/390.0 MB 21.6 MB/s eta 0:00:13\n",
      "   ------------- ------------------------- 132.9/390.0 MB 21.6 MB/s eta 0:00:12\n",
      "   ------------- ------------------------- 137.6/390.0 MB 21.7 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 142.1/390.0 MB 21.7 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 146.8/390.0 MB 21.7 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 151.3/390.0 MB 21.7 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 156.2/390.0 MB 21.7 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 161.0/390.0 MB 21.7 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 165.7/390.0 MB 21.7 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 170.4/390.0 MB 21.7 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 175.4/390.0 MB 21.8 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 180.6/390.0 MB 21.8 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 185.1/390.0 MB 21.8 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 189.8/390.0 MB 21.8 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 194.5/390.0 MB 21.8 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 199.5/390.0 MB 21.8 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 204.2/390.0 MB 21.8 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 208.9/390.0 MB 21.9 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 213.9/390.0 MB 21.9 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 218.6/390.0 MB 21.8 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 223.3/390.0 MB 21.9 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 227.8/390.0 MB 21.9 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 232.3/390.0 MB 21.9 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 237.2/390.0 MB 21.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 242.2/390.0 MB 21.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 247.2/390.0 MB 21.9 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 251.7/390.0 MB 21.9 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 255.9/390.0 MB 21.9 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 260.3/390.0 MB 21.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 265.3/390.0 MB 22.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 269.7/390.0 MB 22.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 274.5/390.0 MB 22.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 279.4/390.0 MB 22.6 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 284.4/390.0 MB 22.6 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 288.9/390.0 MB 22.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 293.3/390.0 MB 22.5 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 297.8/390.0 MB 22.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 302.5/390.0 MB 22.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 307.2/390.0 MB 22.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 312.0/390.0 MB 22.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 316.9/390.0 MB 22.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 321.4/390.0 MB 22.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 325.8/390.0 MB 22.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 330.6/390.0 MB 22.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 335.0/390.0 MB 22.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 339.7/390.0 MB 22.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 344.7/390.0 MB 22.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 349.2/390.0 MB 22.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.0 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.4/390.0 MB 19.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.6/390.0 MB 19.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.6/390.0 MB 19.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.2/390.0 MB 18.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.2/390.0 MB 18.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.2/390.0 MB 18.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.2/390.0 MB 18.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.7/390.0 MB 18.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 354.7/390.0 MB 18.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 355.7/390.0 MB 17.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 358.9/390.0 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 362.8/390.0 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 367.0/390.0 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 371.5/390.0 MB 17.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 375.9/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.9/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.5/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.8/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.8/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.8/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.8/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.8/390.0 MB 17.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.0/390.0 MB 15.9 MB/s eta 0:00:00\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   -------------------------------------- - 4.2/4.4 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 4.5/15.9 MB 20.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.9 MB 20.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.1/15.9 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 18.9 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Using cached rich-13.9.3-py3-none-any.whl (242 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, astunparse, tensorboard, rich, ml-dtypes, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.0\n",
      "    Uninstalling ml_dtypes-0.5.0:\n",
      "      Successfully uninstalled ml_dtypes-0.5.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 numpy-2.0.2 opt-einsum-3.4.0 protobuf-5.28.3 rich-13.9.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 werkzeug-3.0.6 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Danie\\anaconda3\\envs\\XDS\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Danie\\anaconda3\\envs\\XDS\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (2.0.2)\n",
      "Requirement already satisfied: rich in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (13.9.3)\n",
      "Requirement already satisfied: namex in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Collecting tensorflow-probability\n",
      "  Using cached tensorflow_probability-0.24.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-probability) (2.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-probability) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-probability) (2.0.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-probability) (5.1.1)\n",
      "Collecting cloudpickle>=1.3 (from tensorflow-probability)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-probability) (0.6.0)\n",
      "Collecting dm-tree (from tensorflow-probability)\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-win_amd64.whl.metadata (2.0 kB)\n",
      "Using cached tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading dm_tree-0.1.8-cp310-cp310-win_amd64.whl (101 kB)\n",
      "Installing collected packages: dm-tree, cloudpickle, tensorflow-probability\n",
      "Successfully installed cloudpickle-3.1.0 dm-tree-0.1.8 tensorflow-probability-0.24.0\n",
      "Requirement already satisfied: notebook in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (7.2.2)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (6.29.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from notebook) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from notebook) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from notebook) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from notebook) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from notebook) (6.4.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (4.6.2)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (3.1.4)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook) (0.27.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook) (75.1.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.27.1->notebook) (2024.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook) (2.2.3)\n",
      "Requirement already satisfied: executing in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook) (2.9.0.20241003)\n"
     ]
    }
   ],
   "source": [
    "# Ensure pip is up-to-date\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install core data science packages\n",
    "!pip install pandas numpy scikit-learn\n",
    "\n",
    "# Install TensorFlow and TensorFlow Addons compatible with Python 3.8/3.9\n",
    "!pip install tensorflow\n",
    "\n",
    "# Install Keras (integrated with TensorFlow)\n",
    "!pip install keras\n",
    "\n",
    "# Install necessary tools for callbacks and optimizers\n",
    "!pip install tensorflow-probability\n",
    "\n",
    "# Install Jupyter (if youâ€™re working in a notebook environment)\n",
    "!pip install notebook ipykernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdvXLF7igvTo",
    "outputId": "e849483d-5e82-4822-83d9-7756a1f11d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_umdrYgFgxQD",
    "outputId": "13a41a28-77f4-464b-cb1a-e6de215deda5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons==0.16.1\n",
      "  Using cached tensorflow_addons-0.16.1-cp310-cp310-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-addons==0.16.1) (2.13.3)\n",
      "Using cached tensorflow_addons-0.16.1-cp310-cp310-win_amd64.whl (755 kB)\n",
      "Installing collected packages: tensorflow-addons\n",
      "  Attempting uninstall: tensorflow-addons\n",
      "    Found existing installation: tensorflow-addons 0.22.0\n",
      "    Uninstalling tensorflow-addons-0.22.0:\n",
      "      Successfully uninstalled tensorflow-addons-0.22.0\n",
      "Successfully installed tensorflow-addons-0.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons==0.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "adA6mFEngzif",
    "outputId": "c594f828-f7ef-44bd-e9ed-00f09e7a99a3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.20.* in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (3.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf==3.20.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.8.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow-addons==0.16.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (24.3.25)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (3.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (2.0.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow==2.8.0) (1.67.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorflow-addons==0.16.1) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\danie\\anaconda3\\envs\\xds\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.8.0 tensorflow-addons==0.16.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iXobidlTg2B9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Bidirectional,RepeatVector, BatchNormalization, Dropout, Dense, Flatten, Conv1D\n",
    "from keras.layers import MaxPooling1D, GRU, Input,Masking, Concatenate, dot\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.losses import MeanAbsoluteError\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from tensorflow.keras.optimizers import legacy\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "hA2RYVa8hbjL",
    "outputId": "1649d40c-949b-48fa-c20d-8bbf02125ebe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70128, 76)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('UpdatedDataSet.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>Feat 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 67</th>\n",
       "      <th>Feat 68</th>\n",
       "      <th>Feat 69</th>\n",
       "      <th>Feat 70</th>\n",
       "      <th>Feat 71</th>\n",
       "      <th>Feat 72</th>\n",
       "      <th>Feat 73</th>\n",
       "      <th>Feat 74</th>\n",
       "      <th>Feat 75</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.01</td>\n",
       "      <td>7.67</td>\n",
       "      <td>14.67</td>\n",
       "      <td>7.16</td>\n",
       "      <td>6.33</td>\n",
       "      <td>14.59</td>\n",
       "      <td>14.95</td>\n",
       "      <td>8.09</td>\n",
       "      <td>14.73</td>\n",
       "      <td>14.70</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-205.0</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3566.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>24.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.11</td>\n",
       "      <td>-15.25</td>\n",
       "      <td>42.65</td>\n",
       "      <td>-16.14</td>\n",
       "      <td>-25.31</td>\n",
       "      <td>42.00</td>\n",
       "      <td>41.76</td>\n",
       "      <td>-13.63</td>\n",
       "      <td>43.07</td>\n",
       "      <td>42.58</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-188.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3578.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>63.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.15</td>\n",
       "      <td>0.54</td>\n",
       "      <td>50.97</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-8.37</td>\n",
       "      <td>50.40</td>\n",
       "      <td>50.75</td>\n",
       "      <td>2.48</td>\n",
       "      <td>51.33</td>\n",
       "      <td>50.99</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>66.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286.20</td>\n",
       "      <td>8.53</td>\n",
       "      <td>206.96</td>\n",
       "      <td>2.49</td>\n",
       "      <td>-27.06</td>\n",
       "      <td>204.83</td>\n",
       "      <td>206.61</td>\n",
       "      <td>17.17</td>\n",
       "      <td>208.39</td>\n",
       "      <td>207.09</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>2713.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>5422.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>21.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.53</td>\n",
       "      <td>0.98</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1.56</td>\n",
       "      <td>12.91</td>\n",
       "      <td>12.83</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>21.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feat 1  Feat 2  Feat 3  Feat 4  Feat 5  Feat 6  Feat 7  Feat 8  Feat 9  \\\n",
       "0   17.01    7.67   14.67    7.16    6.33   14.59   14.95    8.09   14.73   \n",
       "1   67.11  -15.25   42.65  -16.14  -25.31   42.00   41.76  -13.63   43.07   \n",
       "2   71.15    0.54   50.97   -0.88   -8.37   50.40   50.75    2.48   51.33   \n",
       "3  286.20    8.53  206.96    2.49  -27.06  204.83  206.61   17.17  208.39   \n",
       "4   17.53    0.98   12.82    0.61   -1.13   12.70   12.80    1.56   12.91   \n",
       "\n",
       "   Feat 10  ...  Feat 67  Feat 68  Feat 69  Feat 70  Feat 71  Feat 72  \\\n",
       "0    14.70  ...     33.0   -205.0   3238.0   1938.0   5423.0      0.0   \n",
       "1    42.58  ...     36.0   -188.0   2860.0   1390.0   5423.0      0.0   \n",
       "2    50.99  ...     38.0    -63.0   2721.0   1251.0   5423.0      0.0   \n",
       "3   207.09  ...     29.0    -68.0   2713.0   1193.0   5422.0      0.0   \n",
       "4    12.83  ...     33.0    -68.0   2127.0   1192.0   5423.0      0.0   \n",
       "\n",
       "   Feat 73  Feat 74  Feat 75  Target  \n",
       "0   3566.0    421.0    313.0   24.68  \n",
       "1   3578.0    397.0    310.0   63.18  \n",
       "2   2340.0    449.0    310.0   66.96  \n",
       "3   2238.0    442.0    311.0   21.42  \n",
       "4   1905.0    466.0    305.0   21.47  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x6VLGDEMhBIS"
   },
   "outputs": [],
   "source": [
    "y = df.Target - min(df.Target) +1\n",
    "y= np.log1p(y)\n",
    "x = df.drop(\"Target\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sRF0s7NQhUCq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_PkweW6hWII",
    "outputId": "1572a422-45ed-4759-84a5-45db2fd1091c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56102, 75)\n",
      "(56102,)\n",
      "(14026, 75)\n",
      "(14026,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "B2KIn_P-SFSH"
   },
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JXpOpa3WeSvl"
   },
   "outputs": [],
   "source": [
    "input_shape = (75, 1)\n",
    "encoding_dim = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "s7k4hi0eeV5H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 38), dtype=tf.float32, name=None), name='bidirectional_2/concat:0', description=\"created by layer 'bidirectional_2'\")\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "inputs = Input(shape=input_shape)\n",
    "encoded = Bidirectional(LSTM(encoding_dim, activation='relu'))(inputs)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 75, 1) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Qb_-rL0meYJX"
   },
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoded = RepeatVector(input_shape[0])(encoded)\n",
    "decoded = Bidirectional(LSTM(1, return_sequences=True, activation='relu'))(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LZc2zaLOeaIr"
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tFc1VjdJeuIa"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((-1, x_train.shape[1], 1))\n",
    "x_val = x_val.reshape((-1, x_val.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uU8U25mUeeJN",
    "outputId": "98aa607b-77ca-424e-b9f8-c494d040af4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "839/839 [==============================] - 81s 90ms/step - loss: 1.2607 - val_loss: 0.9119\n",
      "Epoch 2/100\n",
      "839/839 [==============================] - 74s 89ms/step - loss: 0.9394 - val_loss: 0.8508\n",
      "Epoch 3/100\n",
      "839/839 [==============================] - 75s 90ms/step - loss: 0.9037 - val_loss: 0.8452\n",
      "Epoch 4/100\n",
      "839/839 [==============================] - 74s 88ms/step - loss: 0.8973 - val_loss: 0.8464\n",
      "Epoch 5/100\n",
      "839/839 [==============================] - 74s 88ms/step - loss: 0.8889 - val_loss: 0.8421\n",
      "Epoch 6/100\n",
      " 74/839 [=>............................] - ETA: 1:06 - loss: 0.8131"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the autoencoder first\u001b[39;00m\n\u001b[0;32m      2\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1353\u001b[0m              x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1354\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1363\u001b[0m              return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1364\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the loss value & metrics values for the model in test mode.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \n\u001b[0;32m   1367\u001b[0m \u001b[38;5;124;03m  Computation is done in batches (see the `batch_size` arg.)\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;124;03m      x: Input data. It could be:\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;124;03m        - A Numpy array (or array-like), or a list of arrays\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m          (in case the model has multiple inputs).\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;124;03m        - A TensorFlow tensor, or a list of tensors\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m          (in case the model has multiple inputs).\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m        - A dict mapping input names to the corresponding array/tensors,\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;124;03m          if the model has named inputs.\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;124;03m        - A `tf.data` dataset. Should return a tuple\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m          of either `(inputs, targets)` or\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m          `(inputs, targets, sample_weights)`.\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;124;03m        - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;124;03m          or `(inputs, targets, sample_weights)`.\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;124;03m        A more detailed description of unpacking behavior for iterator types\u001b[39;00m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;124;03m        (Dataset, generator, Sequence) is given in the `Unpacking behavior\u001b[39;00m\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;124;03m        for iterator-like inputs` section of `Model.fit`.\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;124;03m      y: Target data. Like the input data `x`, it could be either Numpy\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;124;03m        array(s) or TensorFlow tensor(s). It should be consistent with `x`\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;124;03m        (you cannot have Numpy inputs and tensor targets, or inversely). If\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;124;03m        `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;124;03m        should not be specified (since targets will be obtained from the\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m        iterator/dataset).\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m      batch_size: Integer or `None`. Number of samples per batch of\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;124;03m        computation. If unspecified, `batch_size` will default to 32. Do not\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;124;03m        specify the `batch_size` if your data is in the form of a dataset,\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;124;03m        generators, or `keras.utils.Sequence` instances (since they generate\u001b[39;00m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;124;03m        batches).\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;124;03m      verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;124;03m      sample_weight: Optional Numpy array of weights for the test samples,\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;124;03m        used for weighting the loss function. You can either pass a flat (1D)\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03m        Numpy array with the same length as the input samples\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;124;03m          (1:1 mapping between weights and samples), or in the case of\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;124;03m            temporal data, you can pass a 2D array with shape `(samples,\u001b[39;00m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;124;03m            sequence_length)`, to apply a different weight to every timestep\u001b[39;00m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;124;03m            of every sample. This argument is not supported when `x` is a\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;124;03m            dataset, instead pass sample weights as the third element of `x`.\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;124;03m      steps: Integer or `None`. Total number of steps (batches of samples)\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;124;03m        before declaring the evaluation round finished. Ignored with the\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m        default value of `None`. If x is a `tf.data` dataset and `steps` is\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03m        None, 'evaluate' will run until the dataset is exhausted. This\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;124;03m        argument is not supported with array inputs.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03m      callbacks: List of `keras.callbacks.Callback` instances. List of\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m        callbacks to apply during evaluation. See\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;124;03m        [callbacks](/api_docs/python/tf/keras/callbacks).\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;124;03m      max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03m        input only. Maximum size for the generator queue. If unspecified,\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m        `max_queue_size` will default to 10.\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124;03m      workers: Integer. Used for generator or `keras.utils.Sequence` input\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;124;03m        only. Maximum number of processes to spin up when using process-based\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;124;03m        threading. If unspecified, `workers` will default to 1.\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;124;03m      use_multiprocessing: Boolean. Used for generator or\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;124;03m        `keras.utils.Sequence` input only. If `True`, use process-based\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;124;03m        threading. If unspecified, `use_multiprocessing` will default to\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;124;03m        `False`. Note that because this implementation relies on\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;124;03m        multiprocessing, you should not pass non-picklable arguments to the\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;124;03m        generator as they can't be passed easily to children processes.\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;124;03m      return_dict: If `True`, loss and metric results are returned as a dict,\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;124;03m        with each key being the name of the metric. If `False`, they are\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;124;03m        returned as a list.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m      **kwargs: Unused at this time.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \n\u001b[0;32m   1430\u001b[0m \u001b[38;5;124;03m  See the discussion of `Unpacking behavior for iterator-like inputs` for\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;124;03m  `Model.fit`.\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m \n\u001b[0;32m   1433\u001b[0m \u001b[38;5;124;03m  `Model.evaluate` is not yet supported with\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;124;03m  `tf.distribute.experimental.ParameterServerStrategy`.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[0;32m   1436\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;124;03m      Scalar test loss (if the model has a single output and no metrics)\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;124;03m      or list of scalars (if the model has multiple outputs\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m      and/or metrics). The attribute `model.metrics_names` will give you\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;124;03m      the display labels for the scalar outputs.\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m \n\u001b[0;32m   1442\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;124;03m      RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\u001b[39;00m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;124;03m      ValueError: in case of invalid arguments.\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m   base_layer\u001b[38;5;241m.\u001b[39mkeras_api_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1447\u001b[0m   version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    911\u001b[0m if condition:\n\u001b[0;32m    912\u001b[0m   # Release the lock early so that multiple threads can perform the call\n\u001b[0;32m    913\u001b[0m   # in parallel.\n\u001b[0;32m    914\u001b[0m   self._lock.release()\n\u001b[1;32m--> 915\u001b[0m   # In this case we have created variables on the first call, so we run the\n\u001b[0;32m    916\u001b[0m   # defunned version which is guaranteed to never create variables.\n\u001b[0;32m    917\u001b[0m   return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n\u001b[0;32m    918\u001b[0m elif self._stateful_fn is not None:\n\u001b[0;32m    919\u001b[0m   # Release the lock early so that multiple threads can perform the call\n\u001b[0;32m    920\u001b[0m   # in parallel.\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m   except lift_to_graph.UnliftableError:\n\u001b[0;32m    946\u001b[0m     pass  # Fall through to cond-based initialization.\n\u001b[1;32m--> 947\u001b[0m   else:\n\u001b[0;32m    948\u001b[0m     # Lifting succeeded, so variables are initialized and we can run the\n\u001b[0;32m    949\u001b[0m     # stateless function.\n\u001b[0;32m    950\u001b[0m     return self._stateless_fn(*args, **kwds)\n\u001b[0;32m    951\u001b[0m else:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFunction\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m   2954\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper class for the graph functions defined for a Python function.\u001b[39;00m\n\u001b[0;32m   2955\u001b[0m \n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;124;03m  See the documentation for `defun` for more information on the semantics of\u001b[39;00m\n\u001b[0;32m   2957\u001b[0m \u001b[38;5;124;03m  defined functions.\u001b[39;00m\n\u001b[0;32m   2958\u001b[0m \n\u001b[0;32m   2959\u001b[0m \u001b[38;5;124;03m  `Function` class is thread-compatible meaning that minimal usage of defuns\u001b[39;00m\n\u001b[0;32m   2960\u001b[0m \u001b[38;5;124;03m  (defining and calling) is thread-safe, but if users call other methods or\u001b[39;00m\n\u001b[0;32m   2961\u001b[0m \u001b[38;5;124;03m  invoke the base `python_function` themselves, external synchronization is\u001b[39;00m\n\u001b[0;32m   2962\u001b[0m \u001b[38;5;124;03m  necessary.\u001b[39;00m\n\u001b[0;32m   2963\u001b[0m \u001b[38;5;124;03m  In addition, Function is not reentrant, so recursive functions need to call\u001b[39;00m\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;124;03m  the wrapped function, not the wrapper.\u001b[39;00m\n\u001b[0;32m   2965\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   2967\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2968\u001b[0m                python_function,\n\u001b[0;32m   2969\u001b[0m                name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2976\u001b[0m                jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2977\u001b[0m                experimental_follow_type_hints\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2978\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a `Function`.\u001b[39;00m\n\u001b[0;32m   2979\u001b[0m \n\u001b[0;32m   2980\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3005\u001b[0m \u001b[38;5;124;03m        argspec has keyword arguments.\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     expected, got \u001b[38;5;241m=\u001b[39m spec, arg\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m-> 1853\u001b[0m     expected, got \u001b[38;5;241m=\u001b[39m _structure_summary(spec), _structure_summary(arg)\n\u001b[0;32m   1854\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: argument \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m had incorrect type\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1855\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  expected: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m       got: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1856\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structured_signature_summary(), name, expected,\n\u001b[0;32m   1857\u001b[0m                       got))\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;66;03m# Check the type for each leaf in the nested structure.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    498\u001b[0m   context\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 499\u001b[0m   context\u001b[38;5;241m.\u001b[39madd_function(fn)\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_deleter \u001b[38;5;241m=\u001b[39m _EagerDefinedFunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    501\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_on_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquick_execute\u001b[39m(op_name, num_outputs, inputs, attrs, ctx, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Execute a TensorFlow operation.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    op_name: Name of the TensorFlow operation (see REGISTER_OP in C++ code) to\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m      execute.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    num_outputs: The number of outputs of the operation to fetch.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m                 (Explicitly provided instead of being inferred for performance\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m                 reasons).\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    inputs: A list of inputs to the operation. Each entry should be a Tensor, or\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m      a value which can be passed to the Tensor constructor to create one.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    attrs: A tuple with alternating string attr names and attr values for this\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m      operation.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    ctx: The value of context.context().\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    name: Customized name for the operation.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    List of output Tensor objects. The list is empty if there are no outputs\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    An exception on error.\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m   device_name \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mdevice_name\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the autoencoder first\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(x_train, x_train, epochs=100, batch_size=64, validation_split = 0.125, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XgY-cSSFecb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61362, 75, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train = x_train.reshape((-1, x_train.shape[1], 1))\n",
    "# x_val = x_val.reshape((-1, x_val.shape[1], 1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNku9rjxegIp",
    "outputId": "a0128f57-0b68-42e3-d93f-f27fb3dc5c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000012187464160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000012187464160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "(61362, 38)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Then use the encoder to transform data\n",
    "x_train_encoded = encoder.predict(x_train)\n",
    "x_val_encoded = encoder.predict(x_val)\n",
    "print(x_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIb3HeMZkFan",
    "outputId": "3e22816a-f633-44c5-c88b-a191595e2b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.26739975e-01]\n",
      "  [ 3.23676151e-02]\n",
      "  [-9.50721866e-02]\n",
      "  [ 4.83965914e-02]\n",
      "  [ 1.21049330e-01]\n",
      "  [-9.03212518e-02]\n",
      "  [-1.41115845e-01]\n",
      "  [ 4.25396067e-02]\n",
      "  [-9.68499828e-02]\n",
      "  [-1.11211853e-01]\n",
      "  [ 1.16580328e-01]\n",
      "  [-1.39629261e-01]\n",
      "  [ 5.94396677e-02]\n",
      "  [-2.88545613e-02]\n",
      "  [-8.11009926e-03]\n",
      "  [-1.67297043e-01]\n",
      "  [-8.58417990e-02]\n",
      "  [-1.40882665e-01]\n",
      "  [-1.74112787e-01]\n",
      "  [-2.17291489e-01]\n",
      "  [-2.81828244e-01]\n",
      "  [-2.76185592e-01]\n",
      "  [-3.06299318e-01]\n",
      "  [-3.06444611e-01]\n",
      "  [-3.12525000e-01]\n",
      "  [-3.18306276e-01]\n",
      "  [-2.88035491e-01]\n",
      "  [-2.49753138e-01]\n",
      "  [-2.49008962e-01]\n",
      "  [-2.20224529e-01]\n",
      "  [-1.79866408e-01]\n",
      "  [-1.53900756e-01]\n",
      "  [-1.71405410e-01]\n",
      "  [-1.39355792e-01]\n",
      "  [-1.56713393e-01]\n",
      "  [-1.70658277e-01]\n",
      "  [-1.73478440e-01]\n",
      "  [-1.78225877e-01]\n",
      "  [-1.84150367e-01]\n",
      "  [-1.90706482e-02]\n",
      "  [ 3.14901576e-01]\n",
      "  [ 7.56659038e-02]\n",
      "  [ 3.17575946e+00]\n",
      "  [-1.50130678e-01]\n",
      "  [-2.03579480e-01]\n",
      "  [ 3.89406770e-01]\n",
      "  [ 3.56956942e-02]\n",
      "  [ 1.82601640e-01]\n",
      "  [ 1.41344311e-01]\n",
      "  [ 8.70497744e-02]\n",
      "  [ 1.52402954e+00]\n",
      "  [ 1.24070894e+00]\n",
      "  [ 1.60432485e+00]\n",
      "  [ 2.00231073e+00]\n",
      "  [ 1.72906526e+00]\n",
      "  [ 2.16891017e+00]\n",
      "  [ 8.66669108e-01]\n",
      "  [ 1.86050943e+00]\n",
      "  [ 1.92608431e+00]\n",
      "  [ 1.03553841e+00]\n",
      "  [ 2.23642698e+00]\n",
      "  [ 1.97601462e+00]\n",
      "  [ 1.56001194e+00]\n",
      "  [ 1.37843291e+00]\n",
      "  [ 1.71538095e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  [-8.98737350e-02]\n",
      "  [-9.55489943e-01]\n",
      "  [ 1.99463439e+00]\n",
      "  [-1.00592336e+00]\n",
      "  [-2.06855858e-01]\n",
      "  [ 2.07328506e+00]\n",
      "  [ 1.54732846e+00]\n",
      "  [ 6.52810009e-01]\n",
      "  [-3.29908829e-01]]\n",
      "\n",
      " [[-2.92664455e-01]\n",
      "  [-2.32197917e-01]\n",
      "  [-1.82499925e-01]\n",
      "  [-1.75437931e-01]\n",
      "  [-8.27183167e-02]\n",
      "  [-1.82375726e-01]\n",
      "  [-3.06351723e-01]\n",
      "  [-1.79420452e-01]\n",
      "  [-1.76685604e-01]\n",
      "  [ 2.87183078e+00]\n",
      "  [-8.47499122e-02]\n",
      "  [-3.29482802e-01]\n",
      "  [-3.83889668e-02]\n",
      "  [-6.98449302e-02]\n",
      "  [ 4.02040690e-01]\n",
      "  [-4.07798496e-01]\n",
      "  [-2.17739187e-01]\n",
      "  [-3.59277324e-01]\n",
      "  [-3.62240646e-01]\n",
      "  [-3.12245584e-01]\n",
      "  [-2.81828244e-01]\n",
      "  [-3.16986142e-01]\n",
      "  [-4.37157677e-01]\n",
      "  [-4.60892997e-01]\n",
      "  [-4.30475444e-01]\n",
      "  [-5.99161686e-01]\n",
      "  [-5.99157215e-01]\n",
      "  [-2.15480810e-01]\n",
      "  [-1.74974828e-01]\n",
      "  [-5.16212566e-01]\n",
      "  [-5.15912676e-01]\n",
      "  [-3.64578660e-01]\n",
      "  [-3.16654359e-01]\n",
      "  [-2.73922364e-01]\n",
      "  [-3.21546271e-01]\n",
      "  [-2.64721290e-01]\n",
      "  [-3.49290262e-01]\n",
      "  [-3.12644023e-01]\n",
      "  [-3.84738077e-01]\n",
      "  [-4.66519725e-01]\n",
      "  [-3.41715887e-01]\n",
      "  [ 4.89625702e-02]\n",
      "  [-4.43039818e-01]\n",
      "  [-2.17478632e-01]\n",
      "  [-1.02114154e-01]\n",
      "  [-3.79318751e-01]\n",
      "  [-2.07152990e-01]\n",
      "  [-6.78520669e-01]\n",
      "  [-3.99969307e-01]\n",
      "  [ 5.31084372e-01]\n",
      "  [ 1.53145909e-01]\n",
      "  [ 2.53159226e-01]\n",
      "  [ 5.11926588e-01]\n",
      "  [ 3.50393097e-01]\n",
      "  [ 4.40198068e-01]\n",
      "  [ 7.04531935e-01]\n",
      "  [-9.00612122e-02]\n",
      "  [ 2.54375925e-01]\n",
      "  [ 2.91737877e-01]\n",
      "  [-1.37846469e+00]\n",
      "  [ 6.53826626e-01]\n",
      "  [ 3.73950102e-01]\n",
      "  [ 6.00110175e-01]\n",
      "  [ 1.61378637e-01]\n",
      "  [-2.47117626e-01]\n",
      "  [ 0.00000000e+00]\n",
      "  [-8.78232139e-01]\n",
      "  [-1.44149802e+00]\n",
      "  [ 9.26586457e-01]\n",
      "  [ 1.48779718e-01]\n",
      "  [-6.39202345e-02]\n",
      "  [ 1.00639702e+00]\n",
      "  [ 1.14184123e-01]\n",
      "  [ 7.00057416e-01]\n",
      "  [ 4.04562561e-01]]\n",
      "\n",
      " [[ 1.15190007e+00]\n",
      "  [-1.99375049e-01]\n",
      "  [ 8.03921060e-01]\n",
      "  [-3.27268131e-01]\n",
      "  [-3.49945555e-01]\n",
      "  [ 8.21889340e-01]\n",
      "  [ 5.28227035e-01]\n",
      "  [-2.28840408e-01]\n",
      "  [ 8.12797816e-01]\n",
      "  [ 7.48936887e-01]\n",
      "  [-3.31710363e-01]\n",
      "  [ 1.01337942e+00]\n",
      "  [-3.79821652e-01]\n",
      "  [ 2.91325765e-01]\n",
      "  [-3.78468855e-01]\n",
      "  [ 4.91691015e-02]\n",
      "  [-4.25189225e-02]\n",
      "  [-1.95481330e-01]\n",
      "  [-2.26931019e-01]\n",
      "  [-2.26341801e-01]\n",
      "  [-2.26636186e-01]\n",
      "  [-2.70547698e-01]\n",
      "  [-2.70246504e-01]\n",
      "  [-2.26920753e-01]\n",
      "  [-1.73209947e-01]\n",
      "  [-1.34185006e-01]\n",
      "  [-1.68008083e-01]\n",
      "  [-1.11476903e-01]\n",
      "  [ 3.51100070e-02]\n",
      "  [ 4.41483062e-01]\n",
      "  [-7.02141782e-03]\n",
      "  [-1.91288666e-01]\n",
      "  [-2.36092378e-01]\n",
      "  [-3.66353427e-01]\n",
      "  [-2.10718044e-01]\n",
      "  [-1.61311321e-01]\n",
      "  [-1.90688711e-01]\n",
      "  [-1.17544838e-01]\n",
      "  [-2.45424571e-01]\n",
      "  [ 4.26004693e-01]\n",
      "  [ 4.60289085e-01]\n",
      "  [ 2.33135584e+00]\n",
      "  [ 2.60402655e+00]\n",
      "  [ 2.43276315e-01]\n",
      "  [ 1.03634980e-01]\n",
      "  [-1.68709019e-01]\n",
      "  [ 1.99422233e-01]\n",
      "  [-1.57112590e-01]\n",
      "  [-1.23673815e-01]\n",
      "  [ 2.53451517e-01]\n",
      "  [ 5.16152479e-01]\n",
      "  [ 8.97861495e-01]\n",
      "  [ 1.54414430e-01]\n",
      "  [ 6.63334014e-01]\n",
      "  [ 3.74215106e-01]\n",
      "  [-2.25379135e-01]\n",
      "  [ 1.41944663e+00]\n",
      "  [ 3.65143753e-01]\n",
      "  [ 1.25851714e-01]\n",
      "  [ 1.69910325e+00]\n",
      "  [ 6.41097936e-01]\n",
      "  [ 3.52792521e-01]\n",
      "  [-9.44453241e-02]\n",
      "  [ 3.06882448e-02]\n",
      "  [ 2.05422962e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  [ 9.19225023e-01]\n",
      "  [ 4.56866854e-02]\n",
      "  [ 4.77169354e-01]\n",
      "  [-9.68201664e-01]\n",
      "  [-2.06855858e-01]\n",
      "  [-2.19426711e+00]\n",
      "  [ 3.67921153e-01]\n",
      "  [-2.84671232e-02]\n",
      "  [ 1.21393070e+00]]\n",
      "\n",
      " [[ 1.77133083e+00]\n",
      "  [-2.81322075e-01]\n",
      "  [ 1.33070085e+00]\n",
      "  [-3.66605955e-01]\n",
      "  [-4.89519974e-01]\n",
      "  [ 1.34561490e+00]\n",
      "  [ 9.40520237e-01]\n",
      "  [-2.00907389e-01]\n",
      "  [ 1.34111096e+00]\n",
      "  [ 1.25524043e+00]\n",
      "  [-4.67033543e-01]\n",
      "  [ 2.14933645e+00]\n",
      "  [-2.34046236e-01]\n",
      "  [ 7.96873648e-01]\n",
      "  [-2.29808573e-01]\n",
      "  [-1.18929693e-01]\n",
      "  [ 1.35152816e+00]\n",
      "  [ 1.06829972e+00]\n",
      "  [ 1.10020123e+00]\n",
      "  [ 1.52422596e+00]\n",
      "  [ 2.70373570e+00]\n",
      "  [ 2.42926181e+00]\n",
      "  [ 1.01593390e+00]\n",
      "  [ 1.09842741e+00]\n",
      "  [ 1.06044784e+00]\n",
      "  [ 4.13561840e+00]\n",
      "  [ 1.26123145e+01]\n",
      "  [ 1.12470077e+00]\n",
      "  [ 1.54457548e+00]\n",
      "  [ 1.07500132e+00]\n",
      "  [ 1.67825433e+00]\n",
      "  [ 1.55451901e+00]\n",
      "  [ 1.55199785e+00]\n",
      "  [ 1.94115913e+00]\n",
      "  [ 1.55259316e+00]\n",
      "  [ 1.82602946e+00]\n",
      "  [ 1.77988734e+00]\n",
      "  [ 2.11608120e+00]\n",
      "  [ 1.44636660e+00]\n",
      "  [ 2.00097797e+00]\n",
      "  [ 1.02299809e+00]\n",
      "  [ 3.37506926e-01]\n",
      "  [ 1.24426948e+00]\n",
      "  [ 2.33091455e+00]\n",
      "  [ 4.73894418e-01]\n",
      "  [-1.30146674e-01]\n",
      "  [ 5.94736626e-01]\n",
      "  [ 5.30317224e+00]\n",
      "  [ 4.95114135e+00]\n",
      "  [-2.20030680e+00]\n",
      "  [ 1.25070695e+00]\n",
      "  [ 1.25934196e+00]\n",
      "  [ 3.59652891e-01]\n",
      "  [ 7.55677236e-01]\n",
      "  [ 8.05303790e-01]\n",
      "  [ 9.43743394e-02]\n",
      "  [ 2.12813575e+00]\n",
      "  [ 1.05744268e+00]\n",
      "  [ 6.45637224e-02]\n",
      "  [ 2.76309514e+00]\n",
      "  [ 3.95009946e-01]\n",
      "  [ 5.80858804e-01]\n",
      "  [ 2.91005047e-01]\n",
      "  [ 4.43179794e-01]\n",
      "  [ 1.44712575e+00]\n",
      "  [ 0.00000000e+00]\n",
      "  [ 1.78168123e-01]\n",
      "  [ 1.17322541e+00]\n",
      "  [ 6.13632037e-01]\n",
      "  [-9.04284343e-01]\n",
      "  [-2.10771902e-01]\n",
      "  [-1.55413429e+00]\n",
      "  [-3.37843698e-01]\n",
      "  [-2.11802182e+00]\n",
      "  [ 2.24798911e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[6:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdXjU_q7hGHw",
    "outputId": "08058123-5690-4661-bc8c-d346e0b32da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.55288422e-01 9.68944150e-05 4.49130028e-01 7.93407007e-11\n",
      "  1.56900734e-01 8.24337378e-02 1.45068273e-01 4.12939303e-03\n",
      "  1.89912766e-01 1.11747300e-02 1.31299146e-20 0.00000000e+00\n",
      "  2.54911959e-01 7.00145289e-02 1.58209711e-01 4.19519752e-01\n",
      "  7.33837485e-01 8.45711827e-01 1.68193564e-01 3.52143953e-10\n",
      "  9.26109759e-17 1.02022417e-01 0.00000000e+00 2.71651804e-01\n",
      "  3.81069682e-08 0.00000000e+00 8.82040784e-02 2.14828047e-13\n",
      "  3.88590449e-09 1.48034796e-01 6.46805347e-08 5.38558625e-02\n",
      "  4.36979562e-01 1.17758640e-13 1.26312047e-01 0.00000000e+00\n",
      "  1.47108212e-01 3.19248259e-01]\n",
      " [3.96776652e+00 1.95584523e-17 5.72962880e-01 1.50741090e-03\n",
      "  3.90163809e-01 5.95271774e-02 3.28171328e-02 3.89283746e-02\n",
      "  3.22302245e-02 1.32400664e-27 2.09941348e-21 0.00000000e+00\n",
      "  8.40954900e-01 7.04610255e-03 2.17183426e-01 1.95078226e-16\n",
      "  7.09952772e-01 3.62102151e-01 8.07056644e-10 3.67596442e-09\n",
      "  8.79134823e-05 2.12388515e-01 3.54006363e-04 2.47221082e-01\n",
      "  8.63179666e-05 7.25660296e-11 1.53360181e-02 8.51521716e-02\n",
      "  2.12206016e-03 5.90352230e-02 7.25916703e-04 2.83884746e-03\n",
      "  4.94052738e-01 8.27750191e-02 2.06274778e-01 0.00000000e+00\n",
      "  1.40253715e-02 4.53894466e-01]\n",
      " [1.76707113e+00 2.72769851e-09 7.06143081e-01 5.00321053e-02\n",
      "  3.63904268e-01 6.40663579e-02 1.18515976e-01 3.00448090e-02\n",
      "  8.00372362e-02 2.89866718e-25 1.22794041e-20 5.42183576e-10\n",
      "  5.94533920e-01 6.02422394e-02 7.56333023e-02 3.86864431e-02\n",
      "  5.50798118e-01 4.17668253e-01 5.67629933e-03 1.78782888e-09\n",
      "  1.02109788e-13 1.18589319e-01 0.00000000e+00 2.95375019e-01\n",
      "  2.63354760e-08 2.24409011e-12 2.07560807e-01 2.64969340e-12\n",
      "  3.13829993e-08 2.27662340e-01 4.96239914e-03 5.41420430e-02\n",
      "  3.58974338e-01 3.59564694e-03 7.68264458e-02 2.16024316e-11\n",
      "  2.00341284e-01 2.87788302e-01]\n",
      " [8.87306929e-01 3.40726023e-04 8.02456260e-01 1.77024305e-01\n",
      "  3.87013823e-01 6.23155423e-02 1.77281588e-01 2.24317238e-01\n",
      "  5.82980886e-02 1.16957076e-01 4.45598332e-08 4.83223121e-04\n",
      "  5.88442445e-01 1.20766819e-01 1.97637342e-02 1.17437065e-01\n",
      "  1.26391873e-01 2.91721314e-01 1.73914254e-01 6.24616496e-06\n",
      "  3.15432611e-11 3.22190790e-05 3.30790556e-07 1.48735955e-01\n",
      "  4.09321785e-02 1.55319868e-09 6.56171441e-01 3.68106424e-13\n",
      "  5.74029167e-04 3.47285658e-01 2.74030715e-01 2.15703055e-01\n",
      "  2.20126450e-01 1.34958369e-13 2.88332469e-08 4.24980467e-10\n",
      "  1.01757312e+00 1.22020538e-09]]\n"
     ]
    }
   ],
   "source": [
    "x_train_encoded_flattened = x_train_encoded.flatten()\n",
    "#x_train_diff = pd.DataFrame({'Actual value': x_train.flatten(), 'Predicted value': x_train_encoded_flattened})\n",
    "print(x_train_encoded[6:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Ew2hsfo20eyG"
   },
   "outputs": [],
   "source": [
    "# Encoded input\n",
    "encoded_input = Input(shape=(38,))\n",
    "x = RepeatVector(75)(encoded_input)\n",
    "x = Bidirectional(LSTM(units=100, return_sequences=True, activation=\"relu\", recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "predictions = Dense(1)(x)\n",
    "\n",
    "combined_model = Model(encoded_input, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDjiETMreifE",
    "outputId": "0477a400-0b31-44e0-ae12-4e28dc305354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "959/959 [==============================] - 262s 267ms/step - loss: 28318.9609 - val_loss: 109.6208\n",
      "Epoch 2/100\n",
      "959/959 [==============================] - 252s 263ms/step - loss: 18.0043 - val_loss: 4.2725\n",
      "Epoch 3/100\n",
      "173/959 [====>.........................] - ETA: 3:25 - loss: 4.8894"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Compile and train the combined model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m combined_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1353\u001b[0m              x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1354\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1363\u001b[0m              return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1364\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the loss value & metrics values for the model in test mode.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \n\u001b[0;32m   1367\u001b[0m \u001b[38;5;124;03m  Computation is done in batches (see the `batch_size` arg.)\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;124;03m      x: Input data. It could be:\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;124;03m        - A Numpy array (or array-like), or a list of arrays\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m          (in case the model has multiple inputs).\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;124;03m        - A TensorFlow tensor, or a list of tensors\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m          (in case the model has multiple inputs).\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m        - A dict mapping input names to the corresponding array/tensors,\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;124;03m          if the model has named inputs.\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;124;03m        - A `tf.data` dataset. Should return a tuple\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03m          of either `(inputs, targets)` or\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m          `(inputs, targets, sample_weights)`.\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;124;03m        - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;124;03m          or `(inputs, targets, sample_weights)`.\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;124;03m        A more detailed description of unpacking behavior for iterator types\u001b[39;00m\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;124;03m        (Dataset, generator, Sequence) is given in the `Unpacking behavior\u001b[39;00m\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;124;03m        for iterator-like inputs` section of `Model.fit`.\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;124;03m      y: Target data. Like the input data `x`, it could be either Numpy\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;124;03m        array(s) or TensorFlow tensor(s). It should be consistent with `x`\u001b[39;00m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;124;03m        (you cannot have Numpy inputs and tensor targets, or inversely). If\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;124;03m        `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;124;03m        should not be specified (since targets will be obtained from the\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m        iterator/dataset).\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m      batch_size: Integer or `None`. Number of samples per batch of\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;124;03m        computation. If unspecified, `batch_size` will default to 32. Do not\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;124;03m        specify the `batch_size` if your data is in the form of a dataset,\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;124;03m        generators, or `keras.utils.Sequence` instances (since they generate\u001b[39;00m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;124;03m        batches).\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;124;03m      verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;124;03m      sample_weight: Optional Numpy array of weights for the test samples,\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;124;03m        used for weighting the loss function. You can either pass a flat (1D)\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03m        Numpy array with the same length as the input samples\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;124;03m          (1:1 mapping between weights and samples), or in the case of\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;124;03m            temporal data, you can pass a 2D array with shape `(samples,\u001b[39;00m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;124;03m            sequence_length)`, to apply a different weight to every timestep\u001b[39;00m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;124;03m            of every sample. This argument is not supported when `x` is a\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;124;03m            dataset, instead pass sample weights as the third element of `x`.\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;124;03m      steps: Integer or `None`. Total number of steps (batches of samples)\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;124;03m        before declaring the evaluation round finished. Ignored with the\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m        default value of `None`. If x is a `tf.data` dataset and `steps` is\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03m        None, 'evaluate' will run until the dataset is exhausted. This\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;124;03m        argument is not supported with array inputs.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03m      callbacks: List of `keras.callbacks.Callback` instances. List of\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m        callbacks to apply during evaluation. See\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;124;03m        [callbacks](/api_docs/python/tf/keras/callbacks).\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;124;03m      max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03m        input only. Maximum size for the generator queue. If unspecified,\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m        `max_queue_size` will default to 10.\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;124;03m      workers: Integer. Used for generator or `keras.utils.Sequence` input\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;124;03m        only. Maximum number of processes to spin up when using process-based\u001b[39;00m\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;124;03m        threading. If unspecified, `workers` will default to 1.\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;124;03m      use_multiprocessing: Boolean. Used for generator or\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;124;03m        `keras.utils.Sequence` input only. If `True`, use process-based\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;124;03m        threading. If unspecified, `use_multiprocessing` will default to\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;124;03m        `False`. Note that because this implementation relies on\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;124;03m        multiprocessing, you should not pass non-picklable arguments to the\u001b[39;00m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;124;03m        generator as they can't be passed easily to children processes.\u001b[39;00m\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;124;03m      return_dict: If `True`, loss and metric results are returned as a dict,\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;124;03m        with each key being the name of the metric. If `False`, they are\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;124;03m        returned as a list.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m      **kwargs: Unused at this time.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \n\u001b[0;32m   1430\u001b[0m \u001b[38;5;124;03m  See the discussion of `Unpacking behavior for iterator-like inputs` for\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;124;03m  `Model.fit`.\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m \n\u001b[0;32m   1433\u001b[0m \u001b[38;5;124;03m  `Model.evaluate` is not yet supported with\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;124;03m  `tf.distribute.experimental.ParameterServerStrategy`.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[0;32m   1436\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;124;03m      Scalar test loss (if the model has a single output and no metrics)\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;124;03m      or list of scalars (if the model has multiple outputs\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m      and/or metrics). The attribute `model.metrics_names` will give you\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;124;03m      the display labels for the scalar outputs.\u001b[39;00m\n\u001b[0;32m   1441\u001b[0m \n\u001b[0;32m   1442\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;124;03m      RuntimeError: If `model.evaluate` is wrapped in `tf.function`.\u001b[39;00m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;124;03m      ValueError: in case of invalid arguments.\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m   base_layer\u001b[38;5;241m.\u001b[39mkeras_api_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1447\u001b[0m   version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    911\u001b[0m if condition:\n\u001b[0;32m    912\u001b[0m   # Release the lock early so that multiple threads can perform the call\n\u001b[0;32m    913\u001b[0m   # in parallel.\n\u001b[0;32m    914\u001b[0m   self._lock.release()\n\u001b[1;32m--> 915\u001b[0m   # In this case we have created variables on the first call, so we run the\n\u001b[0;32m    916\u001b[0m   # defunned version which is guaranteed to never create variables.\n\u001b[0;32m    917\u001b[0m   return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n\u001b[0;32m    918\u001b[0m elif self._stateful_fn is not None:\n\u001b[0;32m    919\u001b[0m   # Release the lock early so that multiple threads can perform the call\n\u001b[0;32m    920\u001b[0m   # in parallel.\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m   except lift_to_graph.UnliftableError:\n\u001b[0;32m    946\u001b[0m     pass  # Fall through to cond-based initialization.\n\u001b[1;32m--> 947\u001b[0m   else:\n\u001b[0;32m    948\u001b[0m     # Lifting succeeded, so variables are initialized and we can run the\n\u001b[0;32m    949\u001b[0m     # stateless function.\n\u001b[0;32m    950\u001b[0m     return self._stateless_fn(*args, **kwds)\n\u001b[0;32m    951\u001b[0m else:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFunction\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m   2954\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper class for the graph functions defined for a Python function.\u001b[39;00m\n\u001b[0;32m   2955\u001b[0m \n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;124;03m  See the documentation for `defun` for more information on the semantics of\u001b[39;00m\n\u001b[0;32m   2957\u001b[0m \u001b[38;5;124;03m  defined functions.\u001b[39;00m\n\u001b[0;32m   2958\u001b[0m \n\u001b[0;32m   2959\u001b[0m \u001b[38;5;124;03m  `Function` class is thread-compatible meaning that minimal usage of defuns\u001b[39;00m\n\u001b[0;32m   2960\u001b[0m \u001b[38;5;124;03m  (defining and calling) is thread-safe, but if users call other methods or\u001b[39;00m\n\u001b[0;32m   2961\u001b[0m \u001b[38;5;124;03m  invoke the base `python_function` themselves, external synchronization is\u001b[39;00m\n\u001b[0;32m   2962\u001b[0m \u001b[38;5;124;03m  necessary.\u001b[39;00m\n\u001b[0;32m   2963\u001b[0m \u001b[38;5;124;03m  In addition, Function is not reentrant, so recursive functions need to call\u001b[39;00m\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;124;03m  the wrapped function, not the wrapper.\u001b[39;00m\n\u001b[0;32m   2965\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m   2967\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2968\u001b[0m                python_function,\n\u001b[0;32m   2969\u001b[0m                name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2976\u001b[0m                jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2977\u001b[0m                experimental_follow_type_hints\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2978\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a `Function`.\u001b[39;00m\n\u001b[0;32m   2979\u001b[0m \n\u001b[0;32m   2980\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3005\u001b[0m \u001b[38;5;124;03m        argspec has keyword arguments.\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     expected, got \u001b[38;5;241m=\u001b[39m spec, arg\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m-> 1853\u001b[0m     expected, got \u001b[38;5;241m=\u001b[39m _structure_summary(spec), _structure_summary(arg)\n\u001b[0;32m   1854\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: argument \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m had incorrect type\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1855\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  expected: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m       got: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1856\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structured_signature_summary(), name, expected,\n\u001b[0;32m   1857\u001b[0m                       got))\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;66;03m# Check the type for each leaf in the nested structure.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    498\u001b[0m   context\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 499\u001b[0m   context\u001b[38;5;241m.\u001b[39madd_function(fn)\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_deleter \u001b[38;5;241m=\u001b[39m _EagerDefinedFunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    501\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_on_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquick_execute\u001b[39m(op_name, num_outputs, inputs, attrs, ctx, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Execute a TensorFlow operation.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    op_name: Name of the TensorFlow operation (see REGISTER_OP in C++ code) to\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m      execute.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    num_outputs: The number of outputs of the operation to fetch.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m                 (Explicitly provided instead of being inferred for performance\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m                 reasons).\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    inputs: A list of inputs to the operation. Each entry should be a Tensor, or\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m      a value which can be passed to the Tensor constructor to create one.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    attrs: A tuple with alternating string attr names and attr values for this\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m      operation.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    ctx: The value of context.context().\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m    name: Customized name for the operation.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    List of output Tensor objects. The list is empty if there are no outputs\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    An exception on error.\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m   device_name \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mdevice_name\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "batch_size = 64\n",
    "# Define cyclic learning rate, optimizer, and callback\n",
    "steps_per_epoch = len(x_train) // batch_size\n",
    "cyclic_lr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=1e-04,\n",
    "                                                maximal_learning_rate=1e-02,\n",
    "                                                scale_fn=lambda x: 1/(2**(x-1)),\n",
    "                                                step_size=6 * steps_per_epoch)\n",
    "optimizer = Adam(learning_rate=cyclic_lr, amsgrad=True)\n",
    "\n",
    "\n",
    "# Compile and train the combined model\n",
    "combined_model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "combined_model.fit(x_train_encoded, y_train, validation_data=(x_val_encoded, y_val), epochs=epoch, batch_size=batch_size, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOj8ng7XdhXM",
    "outputId": "d6d53c04-46df-4a80-d812-da5e6b255189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001218738C9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001218738C9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[6.8642755 6.9025826 4.7457647 ... 6.866116  6.75458   6.925442 ]\n",
      "       Actual value  Predicted value\n",
      "32189      7.002256         6.864275\n",
      "41315      7.005880         6.902583\n",
      "57975      7.071106         4.745765\n",
      "14401      7.018026         6.920862\n",
      "8550       7.011998         7.045215\n",
      "...             ...              ...\n",
      "10018      7.010501         7.023081\n",
      "7757       7.007447         6.959826\n",
      "32484      7.005571         6.866116\n",
      "28814      7.009517         6.754580\n",
      "54792      7.040440         6.925442\n",
      "\n",
      "[14026 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test.reshape((-1, x_test.shape[1], 1))\n",
    "# Use encoder to transform x_test and make predictions\n",
    "x_test_encoded = encoder.predict(x_test)\n",
    "y_predict = combined_model.predict(x_test_encoded)\n",
    "\n",
    "y_predict = y_predict.flatten()\n",
    "print(y_predict)\n",
    "diff = pd.DataFrame({'Actual value': y_test, 'Predicted value': y_predict})\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "slqOo4w_KThr"
   },
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uB1SjSXjKJqv",
    "outputId": "15495c6e-0a92-4b48-cc71-58c9bd6abbc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.27376475370671693\n",
      "Mean Absolute percentage Error: 3.864623589888421\n",
      "Root Mean Square Error: 1.768812374224809\n"
     ]
    }
   ],
   "source": [
    "meanAbErr = metrics.mean_absolute_error(y_test, y_predict)\n",
    "meanSqErr = metrics.mean_squared_error(y_test, y_predict)\n",
    "rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_predict))\n",
    "mape= MAPE(y_test,y_predict)\n",
    "#print('R squared: {:.2f}'.format(regr.score(x,y)*100))\n",
    "print('Mean Absolute Error:', meanAbErr)\n",
    "print('Mean Absolute percentage Error:', mape)\n",
    "#print('Mean Square Error:', meanSqErr)\n",
    "print('Root Mean Square Error:', rootMeanSqErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxHHgToKsUSP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
